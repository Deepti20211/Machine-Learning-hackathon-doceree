{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CntMF0zz5Mqb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the train and test data\n",
        "train_data = pd.read_csv('/content/Doceree-HCP_Train.csv', on_bad_lines='skip', encoding='latin1')\n",
        "test_data = pd.read_csv('/content/Doceree-HCP_Test.csv', on_bad_lines='skip', encoding='latin1')\n",
        "\n",
        "# Drop 'TAXONOMY' column from train data\n",
        "train_data = train_data.drop(['TAXONOMY'], axis=1)\n",
        "\n",
        "# Check for missing values in the train data\n",
        "print('Missing values in train data:', train_data.isnull().sum().sum())\n",
        "\n",
        "# Drop rows with missing values in the train data\n",
        "train_data = train_data.dropna()\n",
        "\n",
        "# Split the train data into X and y\n",
        "X_train = train_data.drop(['USERPLATFORMUID', 'IS_HCP'], axis=1)\n",
        "y_train = train_data[['IS_HCP']]\n",
        "\n",
        "# Print the number of missing values in X_train before imputation\n",
        "print('Missing values in X_train before imputation:', X_train.isnull().sum().sum())\n",
        "\n",
        "# Fill in missing values with SimpleImputer\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "\n",
        "# Print the number of missing values in X_train after imputation\n",
        "print('Missing values in X_train after imputation:', X_train.isnull().sum().sum())\n",
        "\n",
        "# Encode the categorical variables using OneHotEncoder\n",
        "ohe = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "X_train_encoded = ohe.fit_transform(X_train)\n",
        "\n",
        "# Train a random forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_encoded, y_train.values.ravel())\n",
        "\n",
        "# Check for missing values in the test data\n",
        "print('Missing values in test data:', test_data.isnull().sum().sum())\n",
        "\n",
        "# Fill in missing values in the test data with SimpleImputer\n",
        "X_test = test_data.drop(['USERPLATFORMUID'], axis=1)\n",
        "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_train.columns)\n",
        "\n",
        "# Encode the categorical variables in the test set using OneHotEncoder\n",
        "X_test_encoded = ohe.transform(X_test)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test_encoded)\n",
        "\n",
        "# Create a dataframe with the predictions and user ids\n",
        "output_df = pd.DataFrame({'USERPLATFORMUID': test_data['USERPLATFORMUID'], 'IS_HCP': y_pred})\n",
        "\n",
        "# Search for the keyword in the 'KEYWORDS' column and print it in 'TAXONOMY' if 'IS_HCP' is 1\n",
        "output_df['TAXONOMY'] = \"\"\n",
        "for i in range(len(output_df)):\n",
        "    prediction = output_df['IS_HCP'].iloc[i]\n",
        "    if prediction == 1:\n",
        "        user_id = output_df['USERPLATFORMUID'].iloc[i]\n",
        "        keywords = train_data[train_data['USERPLATFORMUID'] == user_id]['KEYWORDS'].values\n",
        "        if len(keywords) > 0:\n",
        "            output_df['TAXONOMY'].iloc[i] = keywords[0]\n",
        "\n",
        "# Save the output to a CSV file\n",
        "output_df.to_csv('output.csv', index=False)\n",
        "\n",
        "# Read the output CSV file\n",
        "output_data = pd.read_csv('output.csv')\n",
        "print(output_data)"
      ]
    }
  ]
}